클라우드 elastic에 한국어 애널라이저 사용 기록

일단 elasticsearch에 들어가는 data
유저정보, 게시물 내용, 해시태그

1. user정보 username, introduceName필드 (+introduce 필드, 이건 아직 검색에는 안쓰임.)

2. post 인덱스의 title필드

3. 해시태그 정보 -> post의 tags필드, tags인덱스

3.tags인덱스의 tagName필드는 정확히 검색해야하니 keyword로 매핑해서 그대로 토큰으로 만듦. 근데 어차피 tagName에는 하나의 단어만 들어갈테니 필요없겠지만.. keyword로 명시해놓는게 의도파악에 쉬울거임.
또 id에 어떤것이라도 들어가길래 유니크 보장도 해줄테니 tagName을 그대로 id에 박아버렸는데, 생각하면 할수록 뭔가 아닌거같음.
근데 문제없이 잘 작동하길래 그냥 냅뒀다. 이미 비즈니스 로직에서 존재하는 태그인지 검사 후 삽입하게 해놨긴 한데 음..

3.post의 tags필드는, post의 타이틀에서 #으로 시작하는 글자들을 리스트로 모아 .join(' ') 으로 만들어서 저장함. 여기에는 한국어 분석기 안쓰고 그냥 디폴트 standard 분석기로 해야함. 그래야 공백 토크나이저가 string을 공백기준으로 쪼개서 수정없이 해시태그 그대로 보존해서 토큰으로 저장가능.
그러면 해시태그로 게시물 가져오기 위해 tags필드에 match쿼리를 써서 정확하게 캐치 가능함.

ex) #카페 #아메리카노 로 title업로드 시, '카페 아메리카노'로 post인덱스의 tags 필드에 들어가고, 분석기가 카페, 아메리카노 로 분리해서 색인함. #카페 로 게시물 가져오려고 하면 tags필드에 match '카페'하면 바로 빠르게 가져올것임.

2.post정보의 title는, 검색을 잘되게 하기위해 한국어 분석기 쓰는게 좋다고 판단.
만약 '좋은카페'를 standard가 색인하면 그대로 토큰으로 박아버릴거고,
유저가 '카페'로 검색하면 게시물이 안뜰거임. -> title에는 한국어 분석기 필요.
물론 title에 영어문장이 들어가는걸 가정하면 영어분석기도 추가해야할거임.

1.유저정보는 정확히 검색해야하니 keyWord로 매핑.
prefix로 우선 검색 후, 남는 pageSize에는 '_' + string + '_' 와일드카드로 검색 수행. 와일드카드가.. 얼마나 성능이 나쁠지는 아직은 잘모르겠다. 없애는게 나을지도.
그리고 애초에 사람을 태그하기 위해 username을 검색하는건데, 태그할 상대방 username 을 알고있을 가능성이 다분하니 prefix만으로 검색수행해도 괜찮을거같기도?
와 같이 하기로 생각하고 있었는데.. 매핑과 데이터삽입을 monstache가 해주니 딱히 건드릴 필요가 없어짐. 스탠다드로 색인될테니 데이터 변형도 안될테고. 그냥 냅두면 될듯.

한국어 분석기를 로컬에서 적용해봤자 클라우드에서 적용이 필요하기 때문에 미루고 있었음.
도커에서 노리 분석기 적용이 쉽게 되길래 별생각 없었는데.. 역시 쉽게되는게 없다.

분석기 적용이 어려웠던 원인은,
aws opensearch에서 도메인을 elasticsearch로 해서임.
opensearch로 도메인을 만들면 aws에서 opensearch에 적용하기 쉽게 노리 플러그인을 클릭만 하면 도메인에 추가할 수 있게 해놨음.
근데 엘라스틱서치에는 클릭만해서 추가가 안됨. 별의별짓 다해봤는데, 결국 노리를 쓰는건 실패, 은전한닢으로 적용했음.

노리를 쓸려면 노리 플러그인 파일을 구해서 S3에 올리고 그걸 가져와서 패키지로 만들어야함. 노리 파일을 구하기 위해 로컬에서 노리를 install해서 노리 플러그인 폴더에서 용량 큰 jar파일을 업로드해서 해봤지만, 무슨 수다치? 와 호환안되는 패키지라 실패. 이후 계속 돌아다니면서 파일 찾으려고 시도.

오픈서치 깃헙에 가서 노리 플러그인.java 파일을 발견
https://github.com/opensearch-project/OpenSearch/tree/main/plugins/analysis-nori/src/main/java/org/opensearch/plugin/analysis/nori
이거를 s3에 업로드해서 패키지로 만들어봤음 결과는 성공 했으나,
키바나로 가서 플러그인 보니 노리가 안뜸. ?? repository-s3라는 패키지 뜨긴 했는데, 분석 api로 암만 테스트해봐도 안됨. 노리 이름 넣고 해봐도 안됨.

그래서 기본 깔려있는 은전한닢으로 그냥 적용했음.

또는 프로젝트에 엘라스틱을 opensaerch로 교체하면 그냥 노리 적용이 쉬울듯.

아래는 은전한닢 분석기를 post 인덱스의 title에 적용하는것 기록.

---

키바나 데브툴로 가서 했음.

기존 인덱스 매핑을 유지하면서 분석기를 특정필드에 명시해야함.
기존의 인덱스 세팅에다가 분석기를 추가, 특정필드에 명시까지 해서 새로운 인덱스를 만들어야함.

아무생각없이 시작부터 해서 아주 최적화된 순서는 아님.

1. new 인덱스 만들고 기존 데이터 옮겨옴(+재색인).
2. 기존인덱스 삭제, 다시 new만들었던 form 그대로 새로 기존을 만듦.
3. new의 데이터를 새로만들어진 기존으로 옮겨옴(+재색인)

으로 했는데 그냥

1. 기존 인덱스를 new이름으로 reindex
2. 바꿀 세팅으로 기존을 생성
3. new의 데이터를 기존으로 reindex

하면 빠르고 깔끔.

아니근데 복붙하니까 왜자꾸 '/'뒤에 '\'역슬래시가 붙는거지?
url에서 \ 역슬래시는 지우고 날리길.

GET sns.posts

result

{
"sns.posts" : {
"aliases" : { },
"mappings" : {
"properties" : {
"createdAt" : {
"type" : "date"
},
"tags" : {
"type" : "text"
},
"title" : {
"type" : "text"
}
}
},
"settings" : {
"index" : {
"number_of_shards" : "5",
"provided_name" : "sns.posts",
"creation_date" : "1713172097872",
"analysis" : {
"analyzer" : {
"my_analyzer" : {
"type" : "custom",
"tokenizer" : "seunjeon_tokenizer"
}
}
},
"number_of_replicas" : "1",
"uuid" : "AkIfuTgmSvCD6Jgx0fk0lw",
"version" : {
"created" : "7100299"
}
}
}
}
}
이것이 기본 매핑이었고,

PUT /sns.posts.new
{
"settings": {
"number_of_shards": 5,
"number_of_replicas": 1,
"analysis": {
"analyzer": {
"my_analyzer": {
"type": "custom",
"tokenizer": "seunjeon_tokenizer"
}
}
}
},
"mappings": {
"properties": {
"createdAt": {
"type": "date"
},
"tags": {
"type": "text"
},
"title": {
"type": "text",
"analyzer": "my_analyzer"
}
}
}
}
이렇게 해서 title에만 제대로된 한국어 분석을 위해 은전한닢 토크나이저 적용해서 만든다.

POST /\_reindex
{
"source": {
"index": "sns.posts"
},
"dest": {
"index": "sns.posts.new"
}
}

그후 new인덱스에 기존의 인덱스정보를 가져옴

GET /sns.posts.new/\_search
{
"size": 100,
"query": {
"match_all": {}
}
}
제대로 됐는지 보기위해 기존 문서중에 적당한거 id 가져와서

POST /sns.posts.new/\_termvectors/661df65bc30d6b1daeb34aa2(id)
{
"fields": ["title"],
"offsets": false,
"positions": false,
"term_statistics": true,
"field_statistics": true
}
와 같이 날려주면 분석된 토큰 나옴.

DELETE sns.posts
로 기존 인덱스 날려주고

PUT /sns.posts
{
"settings": {
"number_of_shards": 5,
"number_of_replicas": 1,
"analysis": {
"analyzer": {
"my_analyzer": {
"type": "custom",
"tokenizer": "seunjeon_tokenizer"
}
}
}
},
"mappings": {
"properties": {
"createdAt": {
"type": "date"
},
"tags": {
"type": "text"
},
"title": {
"type": "text",
"analyzer": "my_analyzer"
}
}
}
}
이렇게 아까 new만들때 썼던 인덱스설정 그대로 해서 다시 만든 후

POST /\_reindex
{
"source": {
"index": "sns.posts.new"
},
"dest": {
"index": "sns.posts"
}
}이번엔 posts.new거를 posts에 넣어주면 끝.

마찬가지로 match_all쿼리로 가져와서
\_termvectors 로 확인하면 됨.

제대로 옮겨졌다면 new도 삭제.

아니근데 왜자꾸 '/'뒤에 '\'역슬래시가 붙는거지?
url에서 \ 역슬래시는 지우고 날리길.
